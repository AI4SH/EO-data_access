{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf60183",
   "metadata": {},
   "source": [
    "## Point Data Extraction from the AI4SH Datacube\n",
    "\n",
    "Latest update: 7 December 2025\n",
    "\n",
    "### Overview\n",
    "This Jupyter Notebook extracts static environmental values from the AI4SoilHealth (AI4SH) Datacube for specified in-situ point locations. It reads coordinate points from an Excel file, samples raster layers hosted on the EcoDataCube S3 server, and exports the results to a CSV file.\n",
    "\n",
    "### Purpose\n",
    "The notebook enables researchers to:\n",
    "- Load AI4SH in-situ coordinate points from an Excel file\n",
    "- Convert point data to a GeoDataFrame with proper coordinate reference systems\n",
    "- Extract values from multiple static raster values (terrain derivatives, crop types, etc.)\n",
    "- Handle coordinate reprojection automatically when needed\n",
    "- Save the enriched point data with extracted values\n",
    "\n",
    "### Workflow\n",
    "1. **Environment Setup**: Load required Python libraries (pandas, geopandas, rasterio, numpy)\n",
    "2. **Data Loading**: Read in-situ coordinate points from Excel file\n",
    "3. **Spatial Data Preparation**: Convert points to GeoDataFrame with EPSG:4326 CRS\n",
    "4. **value Selection**: Define list of raster layer URLs from AI4SH Datacube\n",
    "5. **Value Extraction**: Loop through each layer and sample values at point locations\n",
    "6. **Data Export**: Save results to CSV file with all extracted values\n",
    "\n",
    "### Python Package Requirements\n",
    "\n",
    "The Notebook requires the following third party Python packages:\n",
    "- pandas \n",
    "- geopandas \n",
    "- rasterio \n",
    "- numpy \n",
    "- openpyxl \n",
    "- gdal\n",
    "\n",
    "The terminal command for installing these packages with [Anaconda](https://www.anaconda.com) is given below.\n",
    "\n",
    "### Input Requirements\n",
    "- **Excel file**: `AI4SH_in-situ_coordinate_points.xlsx` containing columns for `longitude` and `latitude`\n",
    "- **Directory structure**: Excel file should be located in `../AI4SH_point_locations/` relative to notebook\n",
    "\n",
    "### Output\n",
    "- **CSV file**: `AI4SH_in-situ_points_with_static_values.csv` saved to `../AI4SH_point_data/`\n",
    "- Contains original point data plus columns for each extracted value\n",
    "\n",
    "### Data Sources\n",
    "Static values are accessed from the [AI4SoilHealth SoilHealthDataCube](https://github.com/AI4SoilHealth/SoilHealthDataCube) via HTTPS, including:\n",
    "- Terrain derivatives (slope, curvature, hillshade, TWI, etc.)\n",
    "- Geomorphological features (geomorphons, openness indices)\n",
    "- Topographic indices (LS-factor, shape index)\n",
    "- Land cover/crop type data\n",
    "\n",
    "### Dependencies\n",
    "- Python 3.12\n",
    "- pandas: Data manipulation and Excel/CSV I/O\n",
    "- geopandas: Spatial data operations and coordinate transformations\n",
    "- rasterio: Raster data reading and sampling\n",
    "- numpy: Numerical operations and handling missing values\n",
    "- openpyxl: Excel file reading support\n",
    "- gdal: supports rasterio geo-data processing\n",
    "\n",
    "### Notes\n",
    "- The notebook handles coordinate reprojection automatically when raster CRS differs from point CRS\n",
    "- NoData values are converted to NaN for proper handling in pandas\n",
    "- Progress messages indicate which value is currently being processed\n",
    "- Internet connection required to access remote raster data from S3 server\n",
    "\n",
    "### Licenses\n",
    "The data is provided under the following licenses:\n",
    "\n",
    "- Data License: Creative Commons Attribution license (**CC-BY**)\n",
    "- Code License: Massachusetts Institute of Technology License ()**MIT License**)\n",
    "\n",
    "### Acknowledgments and Funding\n",
    "This work is part of the AI4SoilHealth project, funded by the European Union's Horizon Europe Research and Innovation Programme under Grant Agreement No. 101086179.\n",
    "\n",
    "_Funded by the European Union. The views expressed are those of the authors and do not necessarily reflect those of the European Union or the European Research Executive Agency._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd7194",
   "metadata": {},
   "source": [
    "### Install Python environment\n",
    "Before you run the Notebook you must create a python environment with the required python packages. One way to do that is to install the virtual python environment manager [Anaconda](https://www.anaconda.com/docs/getting-started/anaconda/install). With Anaoconda installed, run the following command from a terminal window to create a virtual python environment (_ai4sh_datacube_access_312_):\n",
    "```\n",
    "conda create -n ai4sh_datacube_access_312 -c conda-forge  pandas geopandas rasterio numpy openpyxl gdal python=3.12 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f1212",
   "metadata": {},
   "source": [
    "### Iinitiate the Notebook\n",
    "Start the notebook and choose your python environment (_ai4sh_datacube_access_312_). You might also be asked to install the additional package **ipykernel** for running the Notebook - the Notebook will pop-up a window and ask for it if required. Aaccept and install the package. Once that is finished the Notebook should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AI4SH in-situ coordinate points dataset and convert to GeoDataFrame\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Third parthy imports\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Get the current working directory\n",
    "notebook_path = os.getcwd()\n",
    "\n",
    "# Get the repository path by going up one level from the notebook path\n",
    "repo_path = os.path.abspath(os.path.join(notebook_path, '..'))\n",
    "\n",
    "# Construct the local path to the directory with the AI4SH in-situ coordinate points\n",
    "point_location_path = os.path.join(repo_path, 'AI4SH_point_locations')\n",
    "\n",
    "# Change the current operating system working directory to the local path with the AI4SH in-situ coordinate points\n",
    "os.chdir(point_location_path)  \n",
    "\n",
    "# Set the file name of the excel file with the AI4SH in-situ coordinate points \n",
    "coordinate_points_excel_file_name = 'AI4SH_in-situ_coordinate_points.xlsx'  \n",
    "\n",
    "# Load the AI4SH in-situ coordinate points dataset\n",
    "AI4SH_points = pd.read_excel(coordinate_points_excel_file_name)\n",
    "\n",
    "# Convert all strings to lowercase to ensure consistency\n",
    "AI4SH_points = AI4SH_points.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# Display the first few rows of the coordinate points dataset\n",
    "print(AI4SH_points.head())\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "geometry = gpd.points_from_xy(AI4SH_points['longitude'], AI4SH_points['latitude'])\n",
    "\n",
    "# print the coordinate reference system (CRS) of the geometry\n",
    "print(geometry.crs)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "AI4SH_points = gpd.GeoDataFrame(\n",
    "    AI4SH_points,\n",
    "    geometry=geometry,\n",
    "    crs='EPSG:4326'  # Global geographic coordinate system (lat/lon)\n",
    ")\n",
    "\n",
    "# Print the CRS of the GeoDataFrame\n",
    "print(AI4SH_points.crs)\n",
    "\n",
    "# When this cell finishes running you should see the first few rows of \n",
    "# the AI4SH in-situ coordinate points dataset and the coordinate \n",
    "# reference system (CRS) of the geometry and GeoDataFrame printed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3f0ee",
   "metadata": {},
   "source": [
    "### List the static values you want to access\n",
    "See the [AI4SoilHealth SoilHealthDataCube](https://github.com/AI4SoilHealth/SoilHealthDataCube) documentation for availability of both static and time varying data that is available. The datacube is regularly updated and more data is continuously being added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of value URLs to rtrieve data from\n",
    "value_urls = [\n",
    "    \"https://s3.ecodatacube.eu/arco/dfme_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/geomorphon_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/hillshade_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/ls.factor_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/maxic_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/minic_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/neg.openness_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/pos.openness_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/pro.curv_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/shpindx_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/slope.in.degree_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/twi_edtm_m_30m_s_20000101_20221231_eu_epsg.3035_v20241230.tif\",\n",
    "    \"https://s3.ecodatacube.eu/arco/crop.type_eucropmap.v1_c_10m_s_20220101_20221231_eu_epsg.3035_v20250416.tif\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e85b33",
   "metadata": {},
   "source": [
    "### Extract the point values from static raster layers\n",
    "Connect to the [AI4SoilHealth SoilHealthDataCube](https://github.com/AI4SoilHealth/SoilHealthDataCube) and sequentially open each dataset (covaraite URL) and loop over the points defined in excel file to retrieve the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a59704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values at point locations\n",
    "\n",
    "# Third parthy imports\n",
    "import rasterio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy of the points GeoDataFrame to store results\n",
    "results = AI4SH_points.copy()\n",
    "\n",
    "# Loop through each value URL and extract values at point locations\n",
    "for url in value_urls:\n",
    "\n",
    "    # Extract value name from URL\n",
    "    value_name = url.split(\"/\")[-1].split(\".tif\")[0]\n",
    "\n",
    "    # Extract the first part of the coviariate name as a simplified name \n",
    "    parts = value_name.split(\"_\")\n",
    "\n",
    "    simplified_name = \"_\".join(parts[:2])\n",
    "\n",
    "    # Print out the simplified value name being processed\n",
    "    print(f\"Processing: {simplified_name}\")\n",
    "\n",
    "    # Open the raster file for the value that is extracted\n",
    "    with rasterio.open(url) as src:\n",
    "\n",
    "        # Reproject points if needed\n",
    "        if AI4SH_points.crs != src.crs:\n",
    "\n",
    "            points_proj = AI4SH_points.to_crs(src.crs)\n",
    "\n",
    "        else:\n",
    "\n",
    "            points_proj = AI4SH_points\n",
    "\n",
    "        # Prepare list of (x, y) coordinates\n",
    "        coords = [(point.x, point.y) for point in points_proj.geometry]\n",
    "\n",
    "        # Sample raster at points\n",
    "        values = []\n",
    "\n",
    "        # Loop through the coordinates listed in the excel file and extract the values\n",
    "        for val in src.sample(coords):\n",
    "\n",
    "            v = val[0]\n",
    "\n",
    "            if v == src.nodata or v is None:\n",
    "\n",
    "                v = np.nan\n",
    "\n",
    "            values.append(v)\n",
    "\n",
    "        # Add the extracted values to the results GeoDataFrame\n",
    "        results[simplified_name] = values\n",
    "\n",
    "# Display the first few rows of the results GeoDataFrame\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2958c",
   "metadata": {},
   "source": [
    "### Save the extracted data\n",
    "Set the file path and name where you want to save the extracted data as a **.csv** file. By defualt the path is direclty under the root of the repositiry and thus a sibling to the folders _notebook_ and _AI4SH_point_locations_ with the name _AI4SH_point_data_, and the default file bane is _AI4SH_in-situ_points_with_static_values.csv_. By editing the puython block below you can change both the path and the filename for svaing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted data to a CSV file\n",
    "\n",
    "# Construct the local path to the directory where you want to save the results\n",
    "point_data_path = os.path.join(repo_path, 'AI4SH_point_data')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(point_data_path):\n",
    "\n",
    "    os.makedirs(point_data_path)\n",
    "\n",
    "# Set the output file path\n",
    "AI4SH_datacube_insitu_point_data_filename = 'AI4SH_in-situ_points_with_static_values.csv'\n",
    "\n",
    "output_file = os.path.join(point_data_path, AI4SH_datacube_insitu_point_data_filename)\n",
    "\n",
    "results.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4sh_datacube_access_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
